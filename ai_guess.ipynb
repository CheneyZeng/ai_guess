{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络学习“你拍我猜” —— 你拍照，AI猜\n",
    "\n",
    "在这个项目中，你将学习利用神经网络来分类照片中是狗狗，是猫猫，还是人。\n",
    "\n",
    "本项目使用了一个经过预处理后较小的数据集，数据集中仅含有图像的特征结果。对于如何获取图像的特征，这里附上了open cv中对于图像特征的说明。\n",
    "http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_meaning/py_features_meaning.html\n",
    "\n",
    "\n",
    "在该 notebook 中，我们基于以下三个特征来了解图像是狗狗，猫猫还是人的概率：\n",
    "\n",
    "- Feature1\n",
    "- Feature2\n",
    "- Feature3\n",
    "- Feature4\n",
    "\n",
    "‘class’是0，代表是人；1代表是猫猫；2代表是狗狗；\n",
    "\n",
    "每一行代表一个图像；\n",
    "\n",
    "## 加载数据\n",
    "\n",
    "为了加载数据并很好地进行格式化，我们将使用两个非常有用的包，即 Pandas 和 Numpy。 你可以在这里阅读文档：\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/\n",
    "- https://docs.scipy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Importing pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    " # present all plots in the notebook\n",
    "\n",
    "# Reading the csv file into a pandas DataFrame\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "#random all the rows in dataset\n",
    "dataset = dataset.sample(frac=1)\n",
    "\n",
    "# print data shortcut\n",
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析 - 绘制数据，可视化的数据分析\n",
    "\n",
    "\n",
    "首先让我们对数据进行绘图，看看他们互相之间的关系是什么。首先来看试一下feature1和feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to help us plot\n",
    "def plot_points(dataset):\n",
    "    X = np.array(dataset[[\"feature1\",\"feature2\"]])\n",
    "    y = np.array(dataset[\"class\"])\n",
    "    \n",
    "    people = X[np.argwhere(y==0)]\n",
    "    cat = X[np.argwhere(y==1)]\n",
    "    dog = X[np.argwhere(y==2)]\n",
    "    \n",
    "    plt.scatter([s[0][0] for s in people], [s[0][1] for s in people], s = 25, color = 'red', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in cat], [s[0][1] for s in cat], s = 25, color = 'cyan', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in dog], [s[0][1] for s in dog], s = 25, color = 'yellow', edgecolor = 'k')\n",
    "    \n",
    "    plt.xlabel('Feature_1')\n",
    "    plt.ylabel('Feature_2')\n",
    "    \n",
    "# Plotting the points\n",
    "plot_points(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图上红色是人，青色是小猫，黄色是小狗。\n",
    "粗略来说，这两个feature并没有很好地分离图像小狗，小猫和人。 也许将另两个features考虑进来会有帮助？ \n",
    "接下来我们将绘制一组图，用seaborn的pairplot函数来试试吧！\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.pairplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting high-dimensional\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(dataset, hue='class', vars=[\"feature1\",\"feature2\",\"feature3\",\"feature4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图上class=0，代表是人；1代表是猫猫；2代表是狗狗；\n",
    "\n",
    "## 任务1: 将训练集拆分成自变量data及应变量标签label的组合\n",
    "\n",
    "数据集中['feature1','feature2','feature3','feature4']是自变量data；\n",
    "\n",
    "['class']则是应变量标签label；\n",
    "\n",
    "可参考使用pandas中的iloc，loc用法。\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.iloc.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.loc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into data - feature table and label table\n",
    "data = None\n",
    "label = None\n",
    "\n",
    "display(data[:10])\n",
    "display(label[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务2: 将分类进行 One-hot 编码\n",
    "\n",
    "为了实现softmax的概率分布，我们将使用Pandas 中的 `get_dummies` 函数来对label进行One-hot编码。\n",
    "\n",
    "### 问题1: one-hot编码的作用是什么呢？\n",
    "\n",
    "回答：（请双击cell进行回答）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Make dummy variables for labels\n",
    "dummy_label = None\n",
    "\n",
    "# Print the first 10 rows of our data\n",
    "dummy_label[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务3: 数据标准化\n",
    "\n",
    "\n",
    "由于神经网络是计算权重，因此我们需要对数据进行标准化的预处理。\n",
    "我们注意到feature2和feature4的范围比feature1和feature3要大很多，这意味着我们的数据存在偏差，使得神经网络很难处理。 让我们将两个特征缩小，使用(x-min)/(max-min))来将特征归到(0, 1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale the columns\n",
    "data['feature2'] = None\n",
    "data['feature4'] = None\n",
    "\n",
    "# Printing the first 10 rows of our procesed data\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务4: 将数据分成训练集和测试集\n",
    "\n",
    "为了测试我们的算法，我们将数据分为训练集和测试集。 测试集的大小将占总数据的 10％。\n",
    "\n",
    "你可以使用numpy.random.choice或者sklearn.model_selection.train_test_split函数。\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "#### 问题2: 拆分测试集的目的是什么？还有其他的拆分方式吗？\n",
    "\n",
    "你的回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split train and test dataset\n",
    "train_data, test_data = \n",
    "train_label, test_label = \n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(train_data[:10])\n",
    "print(test_data[:10])\n",
    "print(train_label[:10])\n",
    "print(test_label[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务5: 训练多分类的神经网络\n",
    "下列函数会训练二层神经网络。 首先，我们将写一些 helper 函数。\n",
    "- Softmax 激活函数\n",
    "\n",
    "$$\\sigma(x) = \\frac{e^{x_i}} {\\sum_{i=1}^{p} e^{x_i}}$$\n",
    "\n",
    "p指代x的特征数量；\n",
    "\n",
    "softmax函数常用于多分类目标的模型，他会把所有的output对sum(output)进行均一化，用于减少模型预测偏差。https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0\n",
    "\n",
    "sigmoid函数常用于二分类目标的模型，他会将离散数值转换为概率数值。https://zh.wikipedia.org/wiki/S%E5%87%BD%E6%95%B0\n",
    "\n",
    "- 误差函数 ：交叉熵\n",
    "\n",
    "$$ loss = - {\\sum_{i=1}^{m} ({y_i} * \\log{\\hat{y_i}})}$$\n",
    "\n",
    "m 为 分类的类别数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Activation (softmax) function\n",
    "def softmax(x):\n",
    "    \n",
    "    return \n",
    "\n",
    "def loss_derivative(x,y,y_hat):\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向误差传递函数\n",
    "\n",
    "现在轮到你来练习，编写误差项。 记住这是由方程 \n",
    "$$  - {x  \\cdot ({y - \\hat{y}})} $$ 给出的。\n",
    "\n",
    "**建议**：此处可以使用numpy.reshape()或者numpy.newaxis()来实现；\n",
    "\n",
    "这里显示了此项目的softmax网络结构。\n",
    "![alt text](softmax.png \"softmax\")\n",
    "\n",
    "下图是softmax的输出模型概览。\n",
    "![alt text](softmax_model.png \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write the error term formula\n",
    "def error_term_formula(x, y, y_hat):\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_nn(features, targets, epochs, learnrate):\n",
    "    \n",
    "    # Use to same seed to make debugging easier\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = np.zeros([features.shape[1],targets.shape[1]])\n",
    "\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        loss = []\n",
    "        for x, y in zip(features.values, targets.values):\n",
    "            # Loop through all records, x is the input, y is the target\n",
    "\n",
    "            # Activation of the output unit\n",
    "            #   Notice we multiply the inputs and the weights here \n",
    "            #   rather than storing h as a separate variable \n",
    "            output = softmax(np.dot(x, weights))\n",
    "            \n",
    "            # The error, the target minus the network output\n",
    "            error = loss_derivative(x, y, output)\n",
    "            loss.append(error)\n",
    "            # The error term           \n",
    "            error_term = error_term_formula(x, y, output)\n",
    "            #print(weights.shape)\n",
    "            del_w -= error_term\n",
    "            \n",
    "        # Update the weights here. The learning rate times the \n",
    "        # change in weights, divided by the number of records to average\n",
    "        weights += learnrate * del_w / n_records\n",
    "\n",
    "        # Printing out the mean square error on the training set\n",
    "        if e % (epochs / 10) == 0:\n",
    "            \n",
    "            out = softmax(np.dot(x, weights))\n",
    "            loss = np.mean(np.array(loss))\n",
    "            print(\"Epoch:\", e)\n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "            last_loss = loss\n",
    "            loss = []\n",
    "            print(\"=========\")\n",
    "    print(\"Finished training!\")\n",
    "    return weights\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务6: 训练你的神经网络\n",
    "\n",
    "设置你的超参数，训练你的神经网络\n",
    "\n",
    "### 问题3: learnrate的设置有什么技巧？\n",
    "\n",
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SET Neural Network hyperparameters\n",
    "epochs = 10\n",
    "learnrate = 0.3\n",
    "weights = train_nn(train_data, train_label, epochs, learnrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务7:计算测试 (Test) 数据的精确度\n",
    "\n",
    "现在你的结果是One-Hot编号后的，想想如何获取的精度上的比较？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate accuracy on test data\n",
    "tes_out = None\n",
    "predictions = None\n",
    "accuracy = None\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务8:用你的神经网络来预测图像是什么\n",
    "\n",
    "在“images/”路径下有两张图片，我们已经使用通过图像提取特征的方式，分别得到了他们的4个feature值，存储在“validations.csv”中。\n",
    "\n",
    "下面就由你来试试，看看你的神经网络能不能准确的预测他们吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Open the 'validations.csv' file and predict the label. \n",
    "# Remember, 0 = people, 1 = cat, 2 = dog\n",
    "valid=pd.read_csv('./images/validations.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务9:（选做）神经网络分类算法的拓展应用\n",
    "\n",
    "经过上面的神经网络训练，我们已经得到一个可以猜对三个对象的网络了！\n",
    "\n",
    "如果想让你的神经网络判断更多的对象，我们就需要提供更多有标签的数据供他学习。\n",
    "\n",
    "同时，我们也要教会我们的神经网络什么是特征（这个部分，我们已经帮你做好了:)）。当我们把神经网络变得更深的时候，多层的神经网络就可以用来提取图像中的特征了！在正式的课程中，我们就会接触到深层网络的实现。\n",
    "\n",
    "在这里，我们先借一个已经训练好能够识别1000个物体的网络来完成“你拍，我猜”的神奇功能吧。你可以随便上传一张照片到“images”的文件夹下，我们的神经网络就可以根据已经学习好的权重来猜你拍的照片是什么哦！快来试试吧！\n",
    "\n",
    "**上传的方法**点击左上方的Jupyter图标，回到上级目录，进入‘/images’文件夹，并upload你所要分类的图片；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet_CAM import *\n",
    "import glob\n",
    "\n",
    "lists = glob.glob('images/*.png')\n",
    "\n",
    "# TODO: Upload your image or pick up any image in the folder 'images/xx.png'\n",
    "for img_path in lists:\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    CAM = plot_CAM(img_path,ax1,ax2,fig)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
